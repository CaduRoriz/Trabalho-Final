# Relat√≥rio da Atividade Extraclasse ‚Äî Aplica√ß√£o Distribu√≠da com gRPC e Kubernetes

### Curso: Engenharia de Software ‚Äì Universidade de Bras√≠lia (UnB/FGA)  
### Disciplina: Programa√ß√£o para Sistemas Paralelos e Distribu√≠dos (PSPD)  
### Professor: Fernando W. Cruz  
### Semestre: 2025/2  
### Participantes: 

|          Aluno               |  Matr√≠cula  | 
|------------------------------|-------------|
|   Luana Souza Silva Torres   |  190033011  |
| Carlos Eduardo Miranda Roriz |  190011424  |


Link do Reposit√≥rio: [link no github](https://github.com/CaduRoriz/Trabalho-Final)

Link do v√≠deo de apresenta√ß√£o: [v√≠deo](adicionar)


## 1. Introdu√ß√£o

Este trabalho teve como objetivo aplicar, na pr√°tica, os conceitos de Programa√ß√£o para Sistemas Paralelos e Distribu√≠dos, utilizando o framework gRPC e o orquestrador de cont√™ineres Kubernetes (Minikube).  

O objetivo est√° em implantar, monitorar e comparar uma aplica√ß√£o distribu√≠da constru√≠da com **gRPC**, executada em um ambiente **Kubernetes em modo cluster** com m√∫ltiplos n√≥s.

Foram realizados:

- **Desenvolvimento dos microservi√ßos** (A, B e P)  
- **Containeriza√ß√£o com Docker**  
- **Orquestra√ß√£o com Kubernetes (Minikube multi-node)**  
- **Monitoramento com Prometheus**  
- **Testes de carga com K6** 
- **Avalia√ß√£o de cen√°rios arquiteturais no cluster**  

A realiza√ß√£o deste trabalho permitiu o aprendizado de tecnologias de sistemas distribu√≠dos como o GRPC, compreender suas vantagens em termos de desempenho e efici√™ncia na comunica√ß√£o bin√°ria, bem como consolidar conhecimentos sobre orquestra√ß√£o containeres em um ambiente Kubernetes muli n√≥, isto √©, em Cluster, assim como a utiliza√ß√£o pr√°tica de tecnologias como o Prometheus.

## 2. Aplica√ß√£o Distribu√≠da

A aplica√ß√£o foi composta por tr√™s servi√ßos em gRPC. Os m√≥dulos est√£o demonstrados a seguir:

| M√≥dulo  |	Linguagem  | Fun√ß√£o |
|---------|------------|--------|
| A	| Python (gRPC/REST) | Contar o n√∫mero de palavras em um texto recebido. |
| B	| Python (gRPC/REST)  |	Contar o n√∫mero de vogais no texto. |
| P	| Node.js | API Gateway, receber requisi√ß√µes HTTP externas e repassar para A e B via gRPC. |

### 2.1 Funcionamento do Sistema

O usu√°rio envia uma requisi√ß√£o HTTP (via Postman) para o servi√ßo P (rota /analyze-text);

O gateway P repassa o texto para os microservi√ßos A e B;

O microservi√ßo A retorna o n√∫mero de palavras e o B retorna o n√∫mero de vogais;

O P agrega os resultados e devolve uma resposta consolidada ao cliente.

Tamb√©m foi considerado o caso da chamada dos microservi√ßos A e B diretamente atrav√©s do uso do grpcurl e do post-forward para permitir abrir uma porta para ambos os servi√ßos.

## 3. Kubernetes

O cluster utilizado foi criado com Minikube multinode, contendo:


|  N√≥  |   Fun√ß√£o    | 
|-----------|------------|
| minikube | Control-plane | 
| minikube-m02 | Worker Node |	
| minikube-m03 |  Worker Node | 

O passo a passo para rodar o kubernetes nessa configura√ß√£o ser√° descrita na se√ß√£o a seguir com o passo a passo de como rodar o projeto por completo. A distribui√ß√£o dos microservi√ßos foi diferente em cada cen√°rio como descrito nas se√ß√µes porteriores.

# Clusteriza√ß√£o utilizando o minikube driver docker cluster kubernetes multi-n√≥

1. Instalar kubectl

No Ubuntu (WSL):

```
sudo apt install -y curl
```

Baixar bin√°rio est√°vel do kubectl:

```
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
```

Dar permiss√£o e mover pro PATH:

```
chmod +x kubectl
sudo mv kubectl /usr/local/bin/
```

Verificar:

```
kubectl version --client
```

2. Instalar Minikube no WSL

No Ubuntu:

```
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
```

Testar:

```
minikube version
```

3. Criar o cluster multi-n√≥

Minikube por padr√£o cria 1 n√≥. Para criar 3 no cen√°rio padr√£o:

```
minikube start --driver=docker --nodes=3
```

p/ verificar:

```
kubectl get nodes
```

4. Subir a aplica√ß√£o no cluster

```
entrar no context:
kubectl config current-context
```

5. Buildar imagens docker localmente na raiz do projeto

```
docker build -t grpc-a:latest -f grpc/A-py/Dockerfile ./grpc
docker build -t grpc-b:latest -f grpc/B-py/Dockerfile ./grpc
docker build -t grpc-p:latest -f grpc/P-nodejs/Dockerfile ./grpc
```

6. Enviar pro cluster multi-n√≥:
```
minikube image load grpc-a:latest
minikube image load grpc-b:latest
minikube image load grpc-p:latest
```

7. Ajuste dos arquivos yalm na pasta k8s j√° configurados

8. Aplicar os arquivos:

P/ aplicar tudo:

```
kubectl apply -f grpc/k8s/namespace.yaml
kubectl apply -f grpc/k8s/
```

9. verificar os pods:
```
kubectl get pods -n pspd-grpc -o wide
```

10. Restart do deployment (apenas se necess√°rio para mudar pods)

```
kubectl rollout restart deployment grpc-a -n pspd-grpc
kubectl rollout restart deployment grpc-b -n pspd-grpc
kubectl rollout restart deployment grpc-p -n pspd-grpc
```

# comunica√ß√£o - para testar 
para ver as portas:
```
kubectl get svc -n pspd-grpc
```

para encontrar a url para se comunicar com o servi√ßo P (http)

```
minikube service grpc-p -n pspd-grpc --url 
```

deve aparecer algo como:
http://127.0.0.1:34559

Teste no postman com a url fornecida pelo m√©todo POST com /analyze-text
ex:
http://127.0.0.1:34585/analyze-text

ap√≥s finalizar aperte Crtl+C no terminal.



# Configurando o Prometheus

1. Instalar helm localmente
```
sudo snap install helm --classic
```

2. Adicionar o reposit√≥rio do Prometheus
```
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

helm repo update
```

3. Instalar kube-prometheus-stack

```
kubectl create namespace monitoring

helm install prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring
```

4. verificar a instala√ß√£o e se est√° rodando 1 exporter para cada pod:

```
kubectl get pods -n monitoring
```

5. Abrir localhost prometheus num terminal separado:

```
kubectl port-forward -n monitoring svc/prometheus-stack-kube-prom-prometheus 9090:9090
```

acesse http://localhost:9090


# Altera√ß√µes para melhorar a observabilidade

Para fazer os testes de carga e isolar os servi√ßos afim de permitir uma an√°lise separada de cada servi√ßo, optamos por utilizar o grpcurl, afim de habilitar a chamada de requisi√ß√µes diretas aos microservi√ßos A e B sem passar por P:


## exemplo para estresse e verificar no Prometheus: Testando servi√ßo A

1. fazer post-forward em um terminal
```
kubectl port-forward svc/grpc-a -n pspd-grpc 50051:50051
```
```
kubectl port-forward svc/grpc-b -n pspd-grpc 50052:50052
```

2. Em outro terminal execute o seguinte comando para fazer 500 requisi√ß√µes ao servi√ßo A
```
for i in {1..50}; do
    grpcurl -plaintext \
      -proto grpc/proto/service.proto \
      -d '{"text":"aaaaaaaaaaaaaaaaaaaa"}' \
      localhost:50051 \
      textanalyzer.WordCounterService.CountWords > /dev/null
done
```

3. Na query do Prometheus voc√™ pode verificar os usos de CPU e Mem√≥ria executando as querys e clicando em Graph:

CPU:
rate(container_cpu_usage_seconds_total{pod=~"grpc-a.*"}[1m])

Mem√≥ria:
container_memory_usage_bytes{pod=~"grpc-a.*"}


## Principais querys Prometheus:

1. ver CPU de todos os pods:

```promql
rate(container_cpu_usage_seconds_total{namespace="pspd-grpc"}[1m])
```

2. CPU por pod:

```promql
rate(container_cpu_usage_seconds_total{pod=~"grpc-a.*"}[1m])
```
```promql
rate(container_cpu_usage_seconds_total{pod=~"grpc-b.*"}[1m])
```
```promql
rate(container_cpu_usage_seconds_total{pod=~"grpc-p.*"}[1m])
```

3. Mem√≥ria de todos os Pods:

```promql
container_memory_usage_bytes{namespace="pspd-grpc"}
```

4. Mem√≥ria por pod:

```promql
container_memory_usage_bytes{pod=~"grpc-a.*"}
```

5. CPU total usada em cada node:

```promql
sum(rate(container_cpu_usage_seconds_total[1m])) by (node)
```

6. Mem√≥ria total por node:

```promql
sum(container_memory_usage_bytes) by (node)
```

7. Ver onde cada pod est√° rodando (distribui√ß√£o dos n√≥s):

```promql
kube_pod_info{namespace="pspd-grpc"}
```

(n√£o retorna gr√°fico, retorna txt com servi√ßo e node)


# üìÑ An√°lise de Resultados ‚Äì Projeto de Paralelismo com Microservi√ßos, Kubernetes, Prometheus e k6


Essa se√ß√£o apresenta a an√°lise dos resultados experimentais obtidos a partir da execu√ß√£o de uma arquitetura de microservi√ßos composta por tr√™s servi√ßos:

- **Servi√ßo P (Gateway REST)** ‚Äì Respons√°vel por receber as requisi√ß√µes HTTP.
- **Servi√ßo A (gRPC)** ‚Äì Respons√°vel pela contagem de palavras.
- **Servi√ßo B (gRPC)** ‚Äì Respons√°vel pela contagem de vogais.

O servi√ßo P recebe uma entrada textual de aproximadamente **5.000 caracteres**, encaminha esta carga simultaneamente aos servi√ßos A e B por meio de chamadas gRPC paralelas e retorna um resultado agregado ao cliente.

O objetivo principal do trabalho √© **avaliar o impacto do paralelismo, da distribui√ß√£o em cluster e da replica√ß√£o de servi√ßos no desempenho do sistema**, utilizando:

- **k6** para testes de carga;
- **Prometheus** para observabilidade (CPU e Mem√≥ria);
- **Docker Stats** para monitoramento direto;
- **Minikube multin√≥** como ambiente de cluster Kubernetes.

---

##  Metodologia Experimental

Para a realiza√ß√£o dos experimentos foram definidos de maneira pr√©via cinco cen√°rios principais de teste. A defini√ß√£o foi realizada anteriormente ao in√≠cio dos testes de modo a evitar qualquer tipo de vi√©s na coleta dos dados. Essa escolha tr√°s consigo uma abordagem acad√™mica da experimenta√ß√£o, mas por outro lado talvez n√£o explore o cen√°rio pr√°tico de paralelismo, a seguir os 5 cen√°rios escolhidos :

| Cen√°rio | Descri√ß√£o |
|--------|-----------|
| Cen√°rio 1 | Execu√ß√£o apenas com Docker, sem cluster |
| Cen√°rio 2 | Cluster Kubernetes com autoscaling |
| Cen√°rio 3 | Todos os servi√ßos no mesmo n√≥ |
| Cen√°rio 4 | Cada servi√ßo em um n√≥ distinto |
| Cen√°rio 5 | Cada servi√ßo com 2 r√©plicas (estresse) |

Para a coleta de resultado dos experimentos foi utilizado a ferramenta de observabilidade Prometheus, e a ferramenta de teste de carga K6.

Os testes de carga foram realizados com o executor `constant-arrival-rate`, variando entre **300, 800, 1500 e at√© 5000 requisi√ß√µes por segundo**.

---

# An√°lise por Cen√°rio

---

## Cen√°rio 1 ‚Äì Execu√ß√£o sem Cluster (Docker Local)

### Descri√ß√£o
Neste cen√°rio, os tr√™s servi√ßos foram executados como containers Docker independentes, sem orquestra√ß√£o por Kubernetes. Foram realizados tr√™s testes:

- **Carga Baixa:** 300 req/s  
- **Carga M√©dia:** 800 req/s  
- **Carga Alta:** ~1200 req/s (limite f√≠sico da m√°quina)

### Principais Resultados (k6)

| Carga | Req/s Efetivo | Lat√™ncia M√©dia | p95 | Erros |
|--------|----------------|----------------|-----|--------|
| Baixa | ~326 | ~70 ms | ~293 ms | 0% |
| M√©dia | ~859 | ~2,3 ms | ~4 ms | 0% |
| Alta | ~1225 | ~1178 ms | ~760 ms | ~0,75% |

### An√°lise

- Em **baixa e m√©dia carga**, o sistema apresentou **excelente estabilidade e baixa lat√™ncia**.
- Em **alta carga**, ocorreram:
  - Satura√ß√£o total de CPU;
  - Lat√™ncias superiores a 1 segundo;
  - Erros de requisi√ß√£o e itera√ß√µes descartadas.

 Conclus√£o:  
A arquitetura **funciona corretamente at√© um limite f√≠sico**, por√©m **n√£o √© escal√°vel sem clusteriza√ß√£o**, tornando o servi√ßo P um **gargalo central**.

---

##  Cen√°rio 2 ‚Äì Cluster Kubernetes com Autoscaling

### Descri√ß√£o
Os servi√ßos passaram a ser gerenciados pelo Kubernetes, com distribui√ß√£o autom√°tica dos pods entre os n√≥s. Em alguns momentos, o servi√ßo P e B ficaram no mesmo n√≥, enquanto o servi√ßo A ficou isolado.

### Resultados

| Carga | Req/s Efetivo | Lat√™ncia M√©dia | Taxa de Erro |
|--------|----------------|----------------|----------------|
| Baixa | ~243 | ~1114 ms | 0% |
| M√©dia | ~532 | ~1059 ms | ~65% |
| Alta | ~1493 | ~329 ms | ~86% |

### An√°lise

Mesmo em **carga baixa**, a lat√™ncia j√° se apresentou **elevada**, indicando:

- Overhead do cluster;
- Satura√ß√£o de n√≥s;
- Gargalos na comunica√ß√£o entre pods.

 Conclus√£o:  
Apenas utilizar Kubernetes com autoscaling **n√£o garante melhoria autom√°tica de desempenho** se n√£o houver planejamento adequado da distribui√ß√£o de carga.

---

##  Cen√°rio 3 ‚Äì Todos os Servi√ßos no Mesmo N√≥

### Descri√ß√£o
Neste cen√°rio, todos os servi√ßos (P, A e B) foram executados dentro de um √∫nico n√≥ do cluster, com teste direto em carga alta (1500 req/s).

### Resultados

| M√©trica | Valor |
|--------|--------|
| Req/s | ~1513 |
| Lat√™ncia M√©dia | ~284 ms |
| p95 | ~1647 ms |
| Taxa de Erro | ~87,5% |

### An√°lise

- Forte conten√ß√£o de CPU;
- Alt√≠ssimo √≠ndice de falhas;
- Gargalo extremo de escalonamento.

 Conclus√£o:  
Este cen√°rio comprova que **colocar todos os servi√ßos em um √∫nico n√≥ anula totalmente o paralelismo**.

---

##  Cen√°rio 4 ‚Äì Cada Servi√ßo em um N√≥ Distinto

### Descri√ß√£o
Cada servi√ßo foi alocado em um n√≥ diferente, sem replica√ß√µes, com carga alta de 1500 req/s.

### Resultados

| M√©trica | Valor |
|--------|--------|
| Req/s | ~1456 |
| Lat√™ncia M√©dia | ~503 ms |
| p95 | ~1251 ms |
| Taxa de Erro | ~87,5% |

### An√°lise

- Distribuir os servi√ßos em n√≥s distintos **reduz a conten√ß√£o direta de CPU**, mas:
  - N√£o elimina gargalos;
  - N√£o evita falhas sob alta carga;
  - Continua existindo ponto √∫nico de falha (servi√ßo P).

Conclus√£o:  
A separa√ß√£o por n√≥s melhora parcialmente o desempenho, mas **n√£o resolve o problema sem replica√ß√£o**.

---

## Cen√°rio 5 ‚Äì Cada Servi√ßo com 2 R√©plicas + Teste de Estresse (5000 req/s)

### Descri√ß√£o
Neste cen√°rio final:

- Cada servi√ßo (P, A, B) possu√≠a **2 r√©plicas (total de 6 pods)**;
- Cluster com **3 n√≥s**;
- Teste em **carga extrema: 5000 req/s**.

### Resultados

| M√©trica | Valor |
|--------|--------|
| Req/s | ~4187 |
| Lat√™ncia M√©dia | ~239 ms |
| p95 | ~1423 ms |
| Taxa de Erro | ~93,6% |
| Throughput Enviado | ~23 MB/s |

### An√°lise

Apesar da arquitetura estar mais distribu√≠da:

- O volume de carga extrapolou a capacidade total do cluster;
- Houve alta taxa de falhas;
- Crescimento absurdo de `http_req_blocked` e `dropped_iterations`.

Conclus√£o:  
Mesmo com **replica√ß√£o**, o sistema possui **limites f√≠sicos claros**, especialmente quando submetido a cargas extremas.

---

# Tabela Comparativa Geral

| Cen√°rio | Arquitetura | Req/s | Lat√™ncia M√©dia | Taxa de Erro | Estabilidade |
|--------|--------------|--------|----------------|----------------|----------------|
| 1 | Docker local | ~1225 | ~1178 ms | ~0,75% | M√©dia |
| 2 | Kubernetes autoscaling | ~1493 | ~329‚Äì1059 ms | At√© 86% | Baixa |
| 3 | Todos no mesmo n√≥ | ~1513 | ~284 ms | ~87% | Muito baixa |
| 4 | Cada servi√ßo em um n√≥ | ~1456 | ~503 ms | ~87% | Baixa |
| 5 | 2 r√©plicas por servi√ßo | ~4187 | ~239 ms | ~93% | Baixa |

---

# 5. Conclus√µes Gerais

A partir da an√°lise dos cinco cen√°rios experimentais realizados, foi poss√≠vel observar de forma pr√°tica e mensur√°vel os impactos diretos do **paralelismo, da clusteriza√ß√£o, da distribui√ß√£o de servi√ßos e da replica√ß√£o de pods no desempenho de sistemas distribu√≠dos**.

Inicialmente, no cen√°rio sem clusteriza√ß√£o (apenas Docker), o sistema apresentou **√≥tima estabilidade em cargas baixas e m√©dias**, mantendo baix√≠ssimos tempos de resposta e aus√™ncia total de falhas. No entanto, √† medida que a carga aumentou, ficou evidente a exist√™ncia de um **limite f√≠sico bem definido da m√°quina host**, caracterizado por:
- Satura√ß√£o de CPU;
- Crescimento abrupto da lat√™ncia;
- Ocorr√™ncia de erros e descarte de itera√ß√µes no k6.

Esse comportamento confirma que, mesmo com chamadas paralelas via gRPC entre os servi√ßos A e B, a aus√™ncia de **distribui√ß√£o de carga em m√∫ltiplos n√≥s** transforma o servi√ßo P (gateway) em um **ponto √∫nico de estrangulamento da arquitetura**.

Com a introdu√ß√£o do Kubernetes, observou-se que a **clusteriza√ß√£o por si s√≥ n√£o garante aumento autom√°tico de desempenho**. Em alguns cen√°rios, especialmente quando m√∫ltiplos servi√ßos foram alocados no mesmo n√≥, houve:
- Alto overhead do ambiente orquestrado;
- Competi√ß√£o por recursos computacionais;
- Aumento significativo da lat√™ncia m√©dia;
- Crescimento expressivo da taxa de falhas.

Isso evidencia que a simples utiliza√ß√£o de um cluster n√£o √© suficiente: √© fundamental que exista **planejamento adequado da distribui√ß√£o dos servi√ßos entre os n√≥s** para que os benef√≠cios da computa√ß√£o distribu√≠da sejam efetivamente alcan√ßados.

Nos testes em que **todos os servi√ßos foram executados em um √∫nico n√≥**, ficou claro que essa configura√ß√£o √© altamente ineficiente sob cargas elevadas. Mesmo com paralelismo l√≥gico entre os servi√ßos, a conten√ß√£o de CPU e mem√≥ria no n√≠vel f√≠sico do n√≥ anulou completamente qualquer ganho arquitetural, ocasionando:
- Taxas de erro superiores a 80%;
- Lat√™ncia extremamente elevada;
- Instabilidade generalizada do sistema.

Quando os servi√ßos passaram a ser distribu√≠dos em **n√≥s distintos**, foi poss√≠vel observar uma melhora moderada na lat√™ncia e um leve ganho de estabilidade. Ainda assim, mesmo nessa configura√ß√£o, o sistema permaneceu vulner√°vel a falhas sob cargas elevadas, principalmente pela aus√™ncia de replica√ß√£o do servi√ßo P, que continuou sendo um **ponto √∫nico de falha**.

O cen√°rio mais robusto estruturalmente foi aquele em que **cada servi√ßo possu√≠a duas r√©plicas**, totalizando seis pods distribu√≠dos no cluster. Nesta configura√ß√£o, foi poss√≠vel alcan√ßar o maior throughput entre todos os experimentos, superando a marca de **4.000 requisi√ß√µes por segundo**, o que demonstra claramente o potencial da **replica√ß√£o aliada √† distribui√ß√£o em m√∫ltiplos n√≥s**. Todavia, mesmo nesse cen√°rio, as cargas extremas impostas (at√© 5.000 req/s) ultrapassaram a capacidade total do ambiente, provocando:
- Elevadas taxas de erro;
- Crescimento do tempo de bloqueio de requisi√ß√µes (`http_req_blocked`);
- Grande quantidade de itera√ß√µes descartadas pelo k6.

Esses resultados demonstram que todo sistema distribu√≠do, independentemente da arquitetura adotada, est√° submetido a **limites f√≠sicos de processamento**, especialmente relacionados a CPU, mem√≥ria, rede e capacidade de escalonamento dos n√≥s.

Al√©m disso, os dados coletados pelo Prometheus foram fundamentais para identificar:
- Picos de utiliza√ß√£o de CPU;
- Crescimento progressivo do consumo de mem√≥ria;
- Momentos de satura√ß√£o completa dos recursos do cluster.

Dessa forma, pode-se concluir que:

- ‚úÖ O **paralelismo via gRPC** entre os servi√ßos A e B √© eficiente e traz ganhos reais de desempenho;
- ‚úÖ A **clusteriza√ß√£o com Kubernetes** oferece escalabilidade estrutural;
- ‚úÖ A **replica√ß√£o de pods** √© essencial para aumentar throughput e toler√¢ncia a falhas;
- ‚ùå A **m√° distribui√ß√£o de servi√ßos entre n√≥s** compromete severamente o desempenho;
- ‚ùå A **aus√™ncia de replica√ß√£o do gateway (servi√ßo P)** torna o sistema altamente vulner√°vel;
- ‚ùå Nenhuma arquitetura √© imune aos **limites f√≠sicos do hardware**.

Por fim, este trabalho evidencia, de forma pr√°tica, que **o desempenho de sistemas distribu√≠dos n√£o depende apenas da ado√ß√£o de tecnologias modernas**, mas principalmente de **decis√µes corretas de arquitetura, distribui√ß√£o de carga e observabilidade cont√≠nua**. O uso combinado de **k6, Prometheus, Docker e Kubernetes** mostrou-se essencial para validar hip√≥teses, identificar gargalos e compreender o comportamento real do sistema sob estresse.

---


# Disponibilidade dos Dados e Materiais

Todos os dados experimentais utilizados para a an√°lise de desempenho deste projeto est√£o dispon√≠veis no pr√≥prio reposit√≥rio, de forma a garantir a **transpar√™ncia, reprodutibilidade e valida√ß√£o dos experimentos apresentados**.

Est√£o disponibilizados no projeto:

-  **Prints das telas do Prometheus**, contendo os gr√°ficos de utiliza√ß√£o de CPU e mem√≥ria em todos os cen√°rios testados;
- **Prints do Docker Stats**, demonstrando em tempo real o consumo de recursos dos containers durante a execu√ß√£o dos testes;
- **Arquivos de sa√≠da em formato JSON do k6**, contendo todas as m√©tricas detalhadas de cada cen√°rio de carga (baixa, m√©dia, alta e estresse).

Esses materiais permitem que qualquer leitor interessado possa:

- Validar os resultados apresentados neste relat√≥rio;
- Reproduzir os testes em ambiente similar;
- Realizar compara√ß√µes com outras arquiteturas e abordagens de paralelismo.

Dessa forma, o projeto atende aos princ√≠pios fundamentais de **reprodutibilidade cient√≠fica e auditabilidade dos resultados**.


# Dificuldades Encontradas

escrever dificuldades *


### Autoavalia√ß√£o:

|          Aluno               |  Contribui√ß√µes  |  Autoavalia√ß√£o |
|------------------------------|-----------------------------------------|-----|
|   Luana Souza Silva Torres   |  Estruturas grpc, prometheus e estrutura√ß√£o do kubernetes, seguido do acompanhamento dos testes de carga  | 10 |
| Carlos Eduardo Miranda Roriz |  Realiza√ß√£o dos testes de carga e acompanhamento da estrutura√ß√£o grpc, prometheus e kubernetes.  | 10 |

### Refer√™ncias:

Refer√™ncias
Site oficial do gRPC: https://grpc.io/
Documenta√ß√£o do Kubernetes: https://kubernetes.io/docs/
Documenta√ß√£o do Minikube: https://minikube.sigs.k8s.io/docs/
Documenta√ß√£o do Prometheus: https://prometheus.io/
Documenta√ß√£o do K6: https://k6.io/